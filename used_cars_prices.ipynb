{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<p align=\"center\"> <img src=\"https://www.motorbiscuit.com/wp-content/uploads/2020/03/Used-Car-Dealership-Getty-5.jpg\"> </p> \r\n",
                "\r\n",
                "# Predicting used cars prices in the Canadian market"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "When it comes to shopping for a used car, budget is one of the main constraints. Prices can differ for a variety of factors, and the experience is quite different than buying a new vehicle. The search process is the first step, and thanks to the internet, the buyer has access to a wealth of information and reviews. With all that said, there is virtually no way to know if an offer is **fair** or **overpriced**. In practice, *prior experience* and *extensive search* can help. How about using machine learning and data analysis to simplify the process and provide **unbiased** advice to the shopper?  \r\n",
                "In the following notebook, I will design and present two machine learning algorithms that will predict used car prices in Canada. The same process could be followed to obtain similar prediction software for the US market.  \r\n",
                " First, an exploratory data analysis (EDA) will be performed on a dataset that will be downloaded from **Kaggle**. In the second step, features will be engineered to train and tune two different machine learning regression algorithms.  \r\n",
                " This project is part of the [Zero to Data Science Bootcamp by Jovian](https://jovian.ai/learn/zero-to-data-analyst-bootcamp)."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1- Download used cars market data  \r\n",
                "In this section, we will install and import all the libraries that will be used throughout the notebook. After that, a large dataset of used cars listings (from Canada and the US) will be downloaded. We will focus on the canadian data, but similar approach can be used to explore the listings from the US."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# download and import the libraries\r\n",
                "\r\n",
                "!pip install opendatasets pandas numpy matplotlib seaborn tqdm sklearn xgboost  --quiet\r\n",
                "import pandas as pd\r\n",
                "import numpy as np\r\n",
                "import seaborn as sns \r\n",
                "import matplotlib.pyplot as plt\r\n",
                "import matplotlib\r\n",
                "from tqdm.notebook import tqdm\r\n",
                "import opendatasets as od\r\n",
                "sns.set_style('darkgrid')\r\n",
                "matplotlib.rcParams['font.size'] = 18\r\n",
                "matplotlib.rcParams['figure.figsize'] = (18, 10)\r\n",
                "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The library `OpenDataSets` by **Jovian** is a conveniant tool to get data from Kaggle. It requires a username and password from the account."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# download data\r\n",
                "filepath = '.\\\\data\\\\marketcheck-automotive-data-us-canada'\r\n",
                "url = 'https://www.kaggle.com/rupeshraundal/marketcheck-automotive-data-us-canada?select=ca-dealers-used.csv'\r\n",
                "if not(os.path.exists(filepath)):\r\n",
                "    od.download_kaggle_dataset(url, filepath)    "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "This will download two seperate `csv` files. Let's explore the `ca-dealers-used.csv` file using `Pandas`."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# read csv data \r\n",
                "canada_ds = pd.read_csv(filepath+'\\\\ca-dealers-used.csv', low_memory=False)\r\n",
                "canada_ds.head(3) "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Each transaction is detailled through multiple columns. The `VIN` number is unique to each car. This field will be used later to remove duplicates. Let's show the properties for each column."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds.info()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "It appears that some columns lack informations for a certain number of transactions. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds.isna().sum()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "We choose to drop all the rows missing pieces of information since we still will have a sufficient amount of data. Before that, we will drop all the columns that won't be used."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "unused_columns = ['id', 'stock_no','seller_name', 'street', 'engine_size',\r\n",
                "                'zip','fuel_type', 'engine_block']\r\n",
                "canada_ds.drop(unused_columns,axis = 1, inplace=True)\r\n",
                "canada_ds.dropna(inplace=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Then, we remove all duplicates using the same `vin` number."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds.drop_duplicates('vin', inplace=True)\r\n",
                "canada_ds.info()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The resulting data frame contains more than 158000 records, with no duplicate and no missing fields. Let's display more details about the column `state`."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#fix state information\r\n",
                "canada_ds.state.unique()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "`OH`, `NC` and `SC` do not represent canadian provinces. To fix this problem, we display the `city` values."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds[canada_ds['state']=='OH']['city'].unique()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "After some search, it turns out that *Woodbridge* is a city in Ontario. We just have to replace the values in the data frame. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds['state'].replace('OH','ON',inplace=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "We proceed the same way with `SC` and `NC`. We found that `NC` doesn't contain any record in a canadian city, and `SC` contains records in **Quebec city, QC**."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds.drop(index = canada_ds[canada_ds.state=='NC'].index, inplace=True)\r\n",
                "canada_ds['state'].replace('SC','QC',inplace=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The column `year` provides the model year of the car. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds['year'].describe()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The data is a snapshot of the listings in 2021, with some cars labeled as from year 2022. This is a common practice in the automotive industry, known as the **model year**. We could create a column `age` using the data from `year`."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# create Age column \r\n",
                "canada_ds['age'] = 2022- canada_ds['year'] "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "One last improvment to our data is to remove outliers, but limiting the age, price and mileage of cars."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# filter very expensive and very old cars (outliers)\r\n",
                "canada_ds=canada_ds[canada_ds['age']<25]\r\n",
                "canada_ds=canada_ds[canada_ds['price']<100000]\r\n",
                "canada_ds=canada_ds[canada_ds['miles']<200000]\r\n",
                "canada_ds.info()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2- Exploratory Data Analysis"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In this section, we will display some graphs to get an intuition about the data that will be used to design the prediction algorithms."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "matplotlib.rcParams['figure.figsize'] = (15, 15)\r\n",
                "fig = sns.scatterplot(y ='price',x='miles', hue = 'age',data =canada_ds,s=25);\r\n",
                "fig.set(xlabel = 'Mileage', ylabel = 'Price', title = 'Relationship between mileage, age and price');"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "It appears that expensive cars are either recent or have low mileage. There are some exceptions (consider the dark points) where some old cars can hold a high value, regardless of the mileage.  \r\n",
                "This next graphs show the most expensive, and the less expensive car makes in the market."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "matplotlib.rcParams['figure.figsize'] = (15, 5)\r\n",
                "column = 'make'\r\n",
                "graph =  canada_ds.groupby(column)['price'].mean().sort_values(ascending=False).head(10)\r\n",
                "fig = sns.barplot(x = graph.values, y = graph.index);\r\n",
                "fig.set(xlabel = 'Price', ylabel = 'Make', title = 'Average price breakdown by make (luxury brands)');\r\n",
                "plt.figure()\r\n",
                "matplotlib.rcParams['figure.figsize'] = (15, 5)\r\n",
                "column = 'make'\r\n",
                "graph =  canada_ds.groupby(column)['price'].mean().sort_values(ascending=True).head(10)\r\n",
                "fig = sns.barplot(x = graph.values, y = graph.index);\r\n",
                "fig.set(xlabel = 'Price', ylabel = 'Make', title = 'Average price breakdown by make (economy brands)');"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's explore which drivetrain is more common in Canada."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "matplotlib.rcParams['figure.figsize'] = (10, 2)\r\n",
                "column = 'drivetrain'\r\n",
                "graph =  canada_ds.groupby(column)['price'].count().sort_values(ascending=False)\r\n",
                "fig = sns.barplot(x = graph.values, y = graph.index);\r\n",
                "fig.set(xlabel = 'Number of listings', ylabel = 'Drivetrain', title = 'Number of listings for each drivetrain type');"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "With no surprise, `4wd` cars are very common in Canada, due to its well-known winter!  \r\n",
                "The next graph will show how `Automatic` transmissions are more prefered in the canadian market."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "matplotlib.rcParams['figure.figsize'] = (10, 1.5)\r\n",
                "column = 'transmission'\r\n",
                "graph =  canada_ds.groupby(column)['price'].count().sort_values(ascending=False)\r\n",
                "fig = sns.barplot(x = graph.values, y = graph.index);\r\n",
                "fig.set(xlabel = 'Number of listings', ylabel = 'Transmission', title = 'Number of listings for each transmission type');"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Used vehicles are more expensive in some provinces, due to standard of living, taxes and emission control. This is shown in the next graph."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "matplotlib.rcParams['figure.figsize'] = (10, 5)\r\n",
                "column = 'state'\r\n",
                "graph =  canada_ds.groupby(column)['price'].mean().sort_values(ascending=False)\r\n",
                "fig = sns.barplot(x = graph.values, y = graph.index);\r\n",
                "fig.set(xlabel = 'Average price', ylabel = 'Province', title = 'Average price for each province');"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The market share of each provice is related to its population size. As we show on the next plot, Ontario has the highest number of listings (and the largest population)."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "matplotlib.rcParams['figure.figsize'] = (10, 5)\r\n",
                "column = 'state'\r\n",
                "graph =  canada_ds.groupby(column)['price'].count().sort_values(ascending=False)\r\n",
                "fig = sns.barplot(x = graph.values, y = graph.index);\r\n",
                "fig.set(xlabel = 'Number of listings', ylabel = 'Province', title = 'Number of listings for each province');"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3- Prepare data for machine learning"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "After cleaning the data, we select the most suitable features to predict/evaluate a used car price. Here is a list of available features in the dataframe: "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "canada_ds.columns"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The output of our model will be obviously the **price**. We will not use the **VIN** number, and split the remaining features into two classes: numeric and categorical columns.  \r\n",
                "Note that a very important piece of information is missing here: **the car condition**. In the used car market, two very identical vehicles can have large price differences due to previous maintenance, accident history, rust, and interior condition. This missing information will affect the precision of the prediction process."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "target_cols = ['price']\r\n",
                "features_num_cols = ['miles', 'age',]\r\n",
                "features_cat_cols = ['make', 'model', 'drivetrain', 'transmission','state', 'city','trim','body_type','vehicle_type']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "raw_data = canada_ds[features_num_cols+features_cat_cols+target_cols].copy()\r\n",
                "print('Average price is ${:.2f}'.format(raw_data['price'].mean()))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The model output (*price*), has an average of $25k. The performance metrics of the regressions will be compared to this value."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "First, we split the data into training, validation and testing sets."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# split train, test and val\r\n",
                "# remove annoying warnings from sklearn\r\n",
                "def warn(*args, **kwargs):\r\n",
                "    pass\r\n",
                "import warnings\r\n",
                "warnings.warn = warn\r\n",
                "\r\n",
                "from sklearn.model_selection import train_test_split\r\n",
                "trainval_data, test_data = train_test_split(raw_data, test_size = 0.2)\r\n",
                "train_data, val_data = train_test_split(trainval_data, test_size = 0.25)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The numeric features will be scaled using *scikit learn* minmax scaler."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# normalize numeric inputs\r\n",
                "from sklearn.preprocessing import MinMaxScaler\r\n",
                "scaler = MinMaxScaler()\r\n",
                "scaler.fit(train_data[features_num_cols])\r\n",
                "train_data[features_num_cols] = scaler.transform(train_data[features_num_cols])\r\n",
                "test_data[features_num_cols] = scaler.transform(test_data[features_num_cols])\r\n",
                "val_data[features_num_cols] = scaler.transform(val_data[features_num_cols])\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The categorical features will be transformed via a one hot encoding strategy."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# one hot encoding categorical inputs\r\n",
                "from sklearn.preprocessing import OneHotEncoder\r\n",
                "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(train_data[features_cat_cols])\r\n",
                "new_one_hot_cols = list(encoder.get_feature_names(features_cat_cols))\r\n",
                "train_data[new_one_hot_cols] = encoder.transform(train_data[features_cat_cols])\r\n",
                "test_data[new_one_hot_cols] = encoder.transform(test_data[features_cat_cols])\r\n",
                "val_data[new_one_hot_cols] = encoder.transform(val_data[features_cat_cols])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "These transformations increase the number of features."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print('number of features ={}'.format(len(features_num_cols + new_one_hot_cols)))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The last step will be to create input and output dataframes for each set."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# create input and output dataframes\r\n",
                "train_inputs = train_data[features_num_cols + new_one_hot_cols]\r\n",
                "test_inputs = test_data[features_num_cols + new_one_hot_cols]\r\n",
                "val_inputs = val_data[features_num_cols + new_one_hot_cols]\r\n",
                "\r\n",
                "train_output = train_data[target_cols]\r\n",
                "test_output = test_data[target_cols]\r\n",
                "val_output = val_data[target_cols]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4- Predicting the price using machine learning "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In this part, we will train and tune two different machine learning regression algorithms. The first method is based on gradient boosting, using the library **XGBoost**."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 4-1 Regression using XGBoost"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn.metrics import mean_squared_error\r\n",
                "from xgboost import XGBRegressor "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "**XGBoost** has multiple hyperparameters. In this notebook, we will tune two parameters:\r\n",
                "- max_depth: Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\r\n",
                "- n_estimators: Number of trees. A high number of trees will most likely lead to overfitting.  \r\n",
                "We will use a grid search method to find the optimal values of these hyperparameters."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "source": [
                "results=[]\r\n",
                "for max_depth in tqdm(range(10,46,5)):\r\n",
                "    for n_estimators in tqdm(range(50,301,50)):\r\n",
                "        model = XGBRegressor(n_estimators = n_estimators, max_depth = max_depth)\r\n",
                "        model.fit(train_inputs, train_output)\r\n",
                "        train_preds = model.predict(train_inputs)\r\n",
                "        val_preds = model.predict(val_inputs)\r\n",
                "        error_train = mean_squared_error(train_output, train_preds, squared=False)\r\n",
                "        error_val = mean_squared_error(val_output, val_preds, squared=False)\r\n",
                "        print('max_depth={} **'.format(max_depth),'n_estimators={} **'.format(n_estimators),\"RMS_error_train = {:.2f} ** RMS_error_val = {:.2f}\".format(error_train,error_val))\r\n",
                "        results.append([max_depth,n_estimators,error_train, error_val, model])"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "639f6e5d5dd54b958b3a404476db6a2f"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "926592890233413280c16b38fb0bd89a"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "max_depth=10 ** n_estimators=50 ** RMS_error_train = 3694.54 ** RMS_error_val = 4315.95\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "- final model selection\r\n",
                "- estimation of RMSE on test set\r\n",
                "- explanation on regression quality\r\n",
                "- a simple example\r\n",
                "- introduce a second ML algorithm (NN?)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# neural network ?\r\n",
                "from keras import models\r\n",
                "from keras import layers\r\n",
                "from keras.callbacks import EarlyStopping\r\n",
                "\r\n",
                "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=10, restore_best_weights=True)\r\n",
                "\r\n",
                "network = models.Sequential()\r\n",
                "network.add(layers.Dense(2000 , activation='relu' , input_dim=len(features_num_cols + new_one_hot_cols))) \r\n",
                "network.add(layers.Dense(2000 , activation='relu')) \r\n",
                "network.add(layers.Dense(1)) \r\n",
                "\r\n",
                "network.compile(optimizer='adam', loss='MeanSquaredError', metrics=['RootMeanSquaredError'])\r\n",
                "\r\n",
                "# Training \r\n",
                "n_epochs =10000\r\n",
                "result = network.fit(train_inputs, train_output,epochs = n_epochs,verbose=1, batch_size = 10000,\r\n",
                "                     validation_data=(val_inputs,val_output),callbacks = [es])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5- Conclusion and future work"
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.9 64-bit"
        },
        "interpreter": {
            "hash": "684b1123683431d89d3bfe9a89cc763215f4b8cd94b4aba1fb40ad45ff7c8b41"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}